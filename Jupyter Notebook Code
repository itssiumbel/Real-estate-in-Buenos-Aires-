import warnings
from glob import glob

import pandas as pd
import seaborn as sns
from category_encoders import OneHotEncoder
from ipywidgets import Dropdown, FloatSlider, IntSlider, interact
from sklearn.impute import SimpleImputer
from sklearn.linear_model import LinearRegression, Ridge  # noqa F401
from sklearn.metrics import mean_absolute_error
from sklearn.pipeline import make_pipeline
from sklearn.utils.validation import check_is_fitted

def wrangle(filepath):
    # Read CSV file
    df = pd.read_csv(filepath)

    # Subset data: Apartments in "Capital Federal", less than 400,000
    mask_ba = df["place_with_parent_names"].str.contains("Capital Federal")
    mask_apt = df["property_type"] == "apartment"
    mask_price = df["price_aprox_usd"] < 400_000
    df = df[mask_ba & mask_apt & mask_price]

    # Subset data: Remove outliers for "surface_covered_in_m2"
    low, high = df["surface_covered_in_m2"].quantile([0.1, 0.9])
    mask_area = df["surface_covered_in_m2"].between(low, high)
    df = df[mask_area]

    # Split "lat-lon" column
    df[["lat", "lon"]] = df["lat-lon"].str.split(",", expand=True).astype(float)
    df.drop(columns="lat-lon", inplace=True)

    # Get place name
    df["neighborhood"] = df["place_with_parent_names"].str.split("|", expand=True)[3]
    df.drop(columns="place_with_parent_names", inplace=True)
    
    # Drop columns wih high % of null
    df.drop(columns=["floor", "expenses"], inplace=True)
    
    # Drop columns with low and high cardinality 
    df.drop(columns=["operation", "property_type", "currency", "properati_url"], inplace=True)
    
    # Drop columns wita leakage
    df.drop(columns=['price', 'price_aprox_local_currency', 'price_per_m2','price_usd_per_m2'], inplace=True)
    
    # Drop columns with multicollinearity
    df.drop(columns=["rooms", "surface_total_in_m2"], inplace=True)
    
    
    return df
    
    # Created a list that contains the filenames for all the Buenos Aires real estate CSV files
    files = glob("data/buenos-aires-real-estate-*.csv")
files


    # Used the wrangle function in a list comprehension to create a list named frames. It contains the cleaned DataFrames for the filenames collected in files
    frames = [wrangle(file) for file in files]
    df = pd.concat(frames, ignore_index=True)
    
    # Created feature matrix X_train and target vector y_train
    features=[]
target = "price_aprox_usd"
features=["surface_covered_in_m2", 
          "lat", 
          "lon", 
          "neighborhood"]
X_train=df[features]
y_train=df[target]
     
     # Calculated the baseline mean absolute error 
     y_mean=y_train.mean()
print("Mean apt price:", y_mean)
y_pred_baseline = [y_mean]*len(y_train)
mean_absolute_error(y_pred_baseline, y_train)
print("Baseline MAE:", mean_absolute_error(y_pred_baseline, y_train))
 
     # Created a pipeline that contains a OneHotEncoder, SimpleImputer, and Ridge predictor
     ohe = OneHotEncoder(use_cat_names=True)
ohe.fit(X_train)
XT_train = ohe.transform(X_train)
imputer = SimpleImputer()
#imputer.fit(X_train)
#XT_train = imputer.transform(X_train)
model =  make_pipeline(
    OneHotEncoder(use_cat_names=True),
    SimpleImputer(),
    Ridge()
)
model.fit(X_train, y_train)

      # Calculated the training mean absolute error for the predictions for comparison to the true targets in y_train
      y_pred_training = model.predict(X_train)
mae_training = mean_absolute_error(y_train, y_pred_training)
print("Training MAE:", round(mae_training, 2))

     # Generated a list of predictions using my model
     X_test = pd.read_csv("data/buenos-aires-test-features.csv")
y_pred_test = pd.Series(model.predict(X_test))
y_pred_test.head()

     # Created a function that takes returns model's prediction for an apartment price
     def make_prediction(area, lat, lon, neighborhood):
    data={
        "surface_covered_in_m2": area, 
          "lat": lat, 
          "lon": lon, 
          "neighborhood": neighborhood
    }
    df=pd.DataFrame(data, index=[0])
    prediction = model.predict(df).round(2)[0]
    return f"Predicted apartment price: ${prediction}"
    
    make_prediction(110, -34.60, -58.46, "Villa Crespo")
    
    # Visualizated the prediction 
    interact(
    make_prediction,
    area=IntSlider(
        min=X_train["surface_covered_in_m2"].min(),
        max=X_train["surface_covered_in_m2"].max(),
        value=X_train["surface_covered_in_m2"].mean(),
    ),
    lat=FloatSlider(
        min=X_train["lat"].min(),
        max=X_train["lat"].max(),
        step=0.01,
        value=X_train["lat"].mean(),
    ),
    lon=FloatSlider(
        min=X_train["lon"].min(),
        max=X_train["lon"].max(),
        step=0.01,
        value=X_train["lon"].mean(),
    ),
    neighborhood=Dropdown(options=sorted(X_train["neighborhood"].unique())),
);
     
